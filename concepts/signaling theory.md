Michael Alvard: "Signaling theory is a theory of communication, and in the context of humans it is fundamentally a theory of culture."

Signals can be more or less reliable (that is, the ostensible signaler's claim matches reality). More reliable signals, inevitably, are (all else equal) the best to target for mimicry. There are assessment signals, where the form of a signal inherently relates to what is signaled, as well as conventional signals and fashion signals (in which the form changes frequently while the meaning stays more or less the same).

# Costly Signaling

_See also the section "Importing costly-signaling theory" section in Symbolic [[Capital]]_

The incentive structure of a society determines, to a large extent, the way its excess resources are put to use. A race-to-the-bottom of self-handicapping fueled Chinese footbinding. In ancestral Melanesian societies, a large section of the male population spends its days in _wabi_ gardens, growing enormous yams in competition with one another, optimizing for size such that the tubers have become inedible. Their labor is akin to leisure [[sports]] such as tennis or suntanning as a style of costly signaling.

On the other hand, there are long histories of churches putting such incentive structures to use in order to built cathedrals, of charities managing enormous contributions, of noble families patronizing the defining art of their centuries. In other words, prestige economies can be _conservational_, and positive-sum, or they can be _wasteful_ and zero-sum. This state of affairs rests largely on what societies and peers reward or punish. (A prestige economy is a technology of behavioral incentive, just as shame is a technology of behavioral disincentive.) Group recognition—suspended reason or illusion—certifies yams as much as cash, since it is the reliable prediction of others assigning value that creates value from social reality (the lesson of crypto, the tulip bubble, and prestige educations). Another prerequisite: the signal ("currency") must be hard to counterfeit.

While receiving and incorporating honestly signaled information into ones decisions gives an organism a fitness advantage, the same behavior predicated on _dishonest_ signals puts one at a _disadvantage_. Thus, to take advantage of the informational benefits of honest signals, organisms must have a way of sorting them from dishonest signals. Honest signals must be _hard or difficult to fake_, and a large subset of hard-to-fake signals is the _costly signal_, where the marginal cost of a display, for organisms which possess a desired trait, is significantly lower than the cost of the same display for organisms lacking that trait. Giving away wealth, for instance, has asymmetrical marginal cost by definition; a charitable donation or bottle service at a club has very different fitness costs for a very wealth versus very poor person. For this reason, reckless expenditure is often taken as a reliable sign of wealth, the very mechanism which Anna Sorokin (Anna "Delvey") used to "swindle N.Y.'s elite" (_New York Times_, 4/25/19) out of almost a quarter million dollars, establishing credibility in her fake identity as "heiress" primarily by giving away large quantities of cash.

What is the situation in which costly signaling is advantageous? There must, one, be variance and opacity in private qualities (Bird & Smith 2005: "attributes that are relatively difficult or expensive to perceive directly"). Two, there must be an informational advantage in having knowledge of the true states of these hidden attributes. Three, there must be an advantage in deceptive signaling, where an organism who has (or appears to have) a certain attribute state is given evolutionarily preferential treatment (e.g., in protected butterflies, will not be preyed upon; see Mimicry and [[surrogation]]). While signaling often takes place in initial encounters between organisms, and fades over relationships, there are several reasons for continued signaling, including _noisy signal meaning_ (individual signal entries are not reliable on their own, and must be aggregated) and the changing nature of the signaled qualities (e.g. health, power, wealth, etc).

_What types of behaviors can be used in costly signaling?_ The behavior must become public knowledge, taking place in some kind of social arena in which the signal can be seen by others. There must be a negative correlation between the behavior's marginal cost and the signaler's unverifiable, hard-to-gauge quality—in other words, costs must be _quality-dependent_. And the behavior must be socially recognized (or effectively treated) as a [[surrogation|proxy]] for the quality.

## Games of skill

If all these conditions are met, then a "design force" (e.g. "decision making, subconscious learning, natural selection, or adaptive cultural transmission") will begin to favor a system of costly-signaling communication. Gift-giving (a la Anna Delvey) is an easy and reliable costly signal of resource control. Games of skill "provide arenas for honest signaling" that games of chance do not. 

**Bird & Smith 2005: Signaling Theory, Strategic Interaction, and Symbolic Capital**:

> [Meriam] top spinners maximize the information-carrying capacity of the signal by eliminating as many randomly generated externalities as possible: competitors create wind-hoods to keep a sudden gust from interfering with their top's spin, use a broken piece of glass as a spinner surface to remove any differences due to friction, and damp down vibrations from overly enthusiast onlookers with a bed of sand.

As Jessica Flack discusses in her interview with Jim Rutt on complex system dynamics, [[sports|sporting]] competitions are a common way for organisms to make mutual inferences about hard-to-gauge qualities:

> ...monkeys have a power structure, what’s typically called a dominance hierarchy. They have fighting abilities that are kind of intrinsic, they develop over time, very slowly, but those fighting abilities are invisible to the other monkeys. The monkeys have to sort of infer what the fighting ability is through fights. That’s how they learn about who’s weaker and stronger.

> And some macaques, like a pigtail macaque, which is one of the species that I’ve worked with, they have this history of fights with other individuals. And over that history, one individual will learn that it’s likely to lose to the other. And if the asymmetry between them is large, so that one individual knows with a high probability it’s going to lose, that individual emits what’s called a subordination signal. And it emits this signal outside of the agonistic or fight context, and it tells the receiver of the signal that the sender recognizes that it’s likely to lose, and has agreed to yield if a conflict in the future arises. The sender is agreeing to a subordinate state in the relationship. So this subordination signal summarizes, there’s a coarse-grained representation of that fight history, and then the two individuals use it.

> They reference it to make decisions about how to behave in the future with each other. Fights do continue, but they continue at a much lower rate, and the idea is that it’s like a background processing... The fights are continuing just so if something changes in the monkeys fighting ability or circumstances, that dominance relationship, that subordination contract can be reversed. Now everyone in the group is doing this, they’re all learning about each other’s fights, and they’re exchanging these signals, and the signal is highly unidirectional, meaning that only one individual in the pair gives a signal. So it’s a very reliable indicator of this role, and now there’s a network of these things, a circuit, if you like. A circuit of these unidirectional signals, and in that circuit is encoded information about the distribution of power.

These inferential practices prevent more conflict from breaking out, and Flack speculates that their equilibrium may well be Bayesian approximate, close to the minimum number of necessary fights to form this informational circuit.

> By using conventional signals such as ceremonial sponsorship or magnanimous behavior to advertise their resource-holding potential, signalers can resolve conflicts before they rise to costlier levels involving direct conflict.

## Unpacking the meaning of "costly"

Costs are not necessarily handicaps; indeed, to individuals of high fitness who engage in such signaling, the costs are usually low. Rather, the behavior would typically be handicapping for individuals of lower fitness, due to its exorbitant marginal cost; that it does _not_ handicap the high-fitness individual is part of its power as signal.

Moreover, costs are not necessarily upfront but can be probabilistic and post-hoc. Bird & Smith 2005, "Signaling Theory, Strategic Interaction, and Symbolic Capital":

> Costs have different sources... Some signals are intrinsically costly to produce... or maintain... Other signals are cheap to produce but entail costs through their potential consequences—especially social consequences (e.g., "status badges" in the plumage of certain bird species or boasting about one's fighting ability in a bar full of rough characters)... This sort of dynamic is relevant to the problem of how human linguistic communication can be kept relatively honest: those who exaggerate their abilities or accomplishments (signal a higher quality than they actually possess) will be punished (pay a disproportionate consequence cost) if their exaggerations are discovered.

Cost in not a prerequisite for honesty either; coincident interests, perfect verifiability of claims, and innate anatomical constraints (e.g. voice and testosterone levels) are two examples of cases in which honesty needs no cost. Indeed, it is when a quality is prone to bullshit that reliable communication requires costly signaling.

## The fashion landscape

_Alva Noë: "We are lost in schemes of organization of which we are not the author and about which we command no clear understanding."_

**Bird & Smith 2005: Signaling Theory, Strategic Interaction, and Symbolic Capital**:

> Since signaling is inherently social, requiring coordination of senders and receivers, any one individual has relatively limited ability to impose novel signals. This set of conditions may encourage the cultural evolution of signals based on conventional meanings that are _relatively_ independent of genetically evolved constraints. If we may paraphrase Marx, while people creatively fashion their own signals, they do not do so with materials of their own free choosing.

## Examples of costly signaling

- Funerary rites: Smith & Bird, 2000
- Distribution of big-game hunting returns: Hawkes & Bird 2002, Bodenhorn 2000
- Big-man feasting: Wiessner & Schiefenhovel 1995
- Northwest Coast Indian potlatches: Boone 2000
- Charity galas: Veblen 1899

# Countersignaling

## Alicorn 2010: Things You Can't Countersignal

> Countersignaling is "showing off by not showing off"—you understate, avoid drawing attention to, or otherwise downplay your communications of and about some valuable trait you have, because a) you are sure you won't be mistaken for someone with very poor characteristics in that area, and b) signaling could make you look like a merely medium-grade specimen.
they're talking about the same thing.
Cases where one is obviously, unmistakeably a quality (unmistakeably to the audience that matters), the additional signaling effort is redundant or even harmful to one's image.

Effective countersignaling otherwise requies being already known, or where the quality in question is already assumed of the entire population: on a [[sports]] team, the most skilled lack the need to "front" to teammates.

> For instance, when I explained my change in life plans to people who are very familiar with me, I was able to use the phrasing "I'm dropping out of school to join a doomsday cult"1 because I knew this sounded so unlike me that none of them would take it at face value.  Alicorn wouldn't really join a doomsday cult; it must be something else!  It elicited curiosity, but not contempt for my cult-joining behavior.  To more distant acquaintances, I used the less loaded term "nonprofit". 

### TIS Commentary

[10:39 PM] suspended reason: But is "countersignaling" really the proper frame for this behavior?

[10:39 PM] suspended reason: The point is that signaling is redundant, unnecessary, showy, declasse etc when the qualities which could be signaled are already well known or obvious to an observer

[10:39 PM] suspended reason: The point is you are beyond signaling

[10:40 PM] suspended reason: You're not "countersignaling" in these cases; it's not a strategic move to further increase your status. They're cases where hidden qualities are not hidden therefore, no need for signaling, whose entire point is communicating hidden qualities

[10:41 PM] suspended reason: This makes me wonder when countersignaling is actually happening, and if, when it does happen, it can't be equally framed as "costly signaling" (I can get away with wearing tshirt and flipflops b/c I'm the CEO; you can't as an employee; there's a marginal cost differential which is what definitionally enables the costly signal)

[10:41 PM] suspended reason: "Countersignaling" is a common concept in rationalist circles, but I'm starting to become skeptical

# Layers of signaling

**Bird & Smith 2005: Signaling Theory, Strategic Interaction, and Symbolic Capital**:

> Signaling theory in the social realm has tended to focus on the symbolic capital accruing to groups as a result of signaling by members, while theory in evolutionary ecology tends to focus on the benefits to individuals. There is no reason to suspect that one or the other must take precedence: individuals may often signal competitively in order to gain benefits for themselves and may also cooperate with other members of a coalition or social group to signal group attributes to other such groups. In many cases, the two levels of signaling may be intertwined (as in the Meriam feasting complex).

# Examples

## Footbinding & body modification

**Bird & Smith 2004: Signaling Theory, Strategic Interaction, and Symbolic Capital**

> Finally, there are plausible grounds for expecting signaling theory to illuminate costly and often seemingly irrational forms of bodily modification, ranging from tattoos and scarification to genital cutting (male and female) and footbinding. Some preliminary research has explored the hypothesis that bloodletting and intensive forms of body modification may serve to test nutritional status or immunocompetence in environments with high rates of pathogens (Ludvico and Kurland 1995, Neiman 1997, Singh and Bronstad 1997). Alternative hypotheses exist for these practices, of course, ranging from providing irreversible markers of ethnic affiliation to heightening the emotional impact of initiation rites, and we do not necessarily expect signaling explanations to be the sole or even predominant explanation for ritualized bodily modification. 

> In some instances, such as Chinese footbinding, historical evidence indicates that the practice began as a way for high-status individuals (in this case, elite concubines) to differentiate themselves from social competitors as women of leisure. It then spread via competitive emulation to all but the poorest peasant classes, who could not afford the reduction in female mobility (and thus field labor) it entailed (Stevan Harrell, personal communication; Gates 2001).

# Hard-to-forge documents

From Schelling's _Strategies of Conflict_ (see also [[Strategic Interaction]]):

"It is easier to prove the truth of something that is true than of something that is false." All "certification" (seals, stamps, barcodes, certificates, etc) are just built on top of costly signaling technology. It is not that they can't be faked. It is that they are too expensive (in time as well as money) to fake, and therefore a rational agent can't be bothered—the benefit of faking the document isn't worth the cost, so you can ensure all (or vast majority) of such certificates are authentic. The seal alone does not certify; what certifies is the cost of forging, which is asymmetrically demanded of those who have not secured the certificate by legitimate means.

# Motive ambiguity

[[Zvi]] on motive [[ambiguity]]:

> You are married, and want to take your spouse out to a romantic dinner. You could choose a place you both love, or a place that only they love. You choose the place you don’t love, so they will know how much you love them. After all, you didn’t come here for the food.

The greater one's sacrifice toward some end, the stronger the signal they are invested in that end. 

As a result, human beings may choose the less desirable option, given two choices which equally satisfice some end X, because that option has no other benefit to it _other_ than achieving X. This makes it a non-ambiguous signal for caring about achieving X. As a result, real value is deferred or destroyed for the sake of symbolic value.

A similar anecdote crops up in _1984_:

> ‘How does one man assert his power over another, Winston?’
> Winston thought. ‘By making him suffer,’ he said.
> ‘Exactly. By making him suffer. Obedience is not enough.
> Unless he is suffering, how can you be sure that he is obeying your will and not his own?'

Here, allegiance or submission to another is demonstrated via suffering—because behavior which is desirable to the powerless _and_ the powerful entities in question would not unamibuously display loyalty.

See also norms for cult initiation where in-group loyalty is proved by swearing epistemic allegiance to a patently absurd concept.

# Signals vs Cues

_See also "Communication vs Expression" section in [[Strategic Interaction]] entry._

Classically, _reliable_ signals are ones that can always be trusted (by a receiver) as honest. _Unreliable_ signals may or may not be honest. Unreliable signals' efficacy is _frequency dependent_: the ratio of honest to dishonest systems in an ecosystem, modified by the relative costs of acting on vs. ignoring the signal, entails the optimal behavior of a receiver. If eating a poison dart frog is fatal, it may only take 5% of all bright red frogs being poisonous to protect the entire population from predators (that is, to protect the other 95% of free-riding, deceptive signalers). On the other hand, if eating a dart frog is merely unpleasant for the predator, it may take upwards of 95% honest signals in the ecosystem for that species to leave bright red frogs alone. 

Transcending the reliable/unreliable binary, we can call signals with a high percentage of honesty, in the ecosystem, more reliable; signals that are only sometimes honest we'll call more unreliable.

What does this tell us? That, all else being equal—controlling for the relative cost of ignoring vs acting on a signal, as well as the relative cost of faking the signal—the most effective signals for a free-riding mimic to target are those which are already most reliable.

[[Erving Goffman|Goffman]] (ostensibly unknowingly, but he cites only rarely) recreates this insight from signaling theory in his own expression games. In expression games, many kinds of communication cannot be trusted by the observer. For instance, it is in individuals' self-interest to present themselves as flatteringly as possible ([[opticratics]]), rather than as honestly as possible; moreover, many individuals will fully fabricate biographical details for the sake of competitive advantage. In such a landscape, observers (i.e. evaluators) are forced to rely on certain "very special signs on which he puts great weight," and believes he can rely.

> The very tendency of the observer to suspect the subject and try to seek out means of piercing the veil means that the observer will shift his reliance to the very special signs on which he puts great weight; and if these signs can be discovered and faked by the subject, the latter will find himself dealing, in effect, with an ingenuous opponent.

I'll call these "evaluative bottlenecks." In an old book club call with @[[thechickenman]] and @crispy, discussing McLuhan, I shared an anecdote about drug trafficking. When the means by which a subject will be observed or evaluated are limited ("bottlenecked"), and known in advance, they are at their most vulnerable. If a trafficker does not know how he will be evaluated—if the inspection agents may possibly have x-ray, metal detector, drug sniffing dogs, full body patting, etc—then it is difficult for him to optimize his deceitful self-expression. There are many different potential tests he will be subject to, and optimizing performance across all those tests gets increasingly difficult, as the space of possible solutions to all of them shrinks. However, if there is only a _single_ type of test, and it is known in advance, we reach a bottleneck scenario in which the trafficker need only optimize his hiding place for a single "uncovering move" ([[Erving Goffman|Goffman]]'s term for any move that attempts to unveil the truth below surface impressions).

These kinds of highly valued tests, or uncovering moves, or measurements, or sought-after signs are weighted in proportion to their purported reliability. If we see a DNA test as authoritative, and our courts will throw out even witness testimonies and criminal confessions in favor of a DNA test, perceiving it to be always reliable, then there is now only one, single aspect a defense attorney must fabricate or tamper with in order to get his client off. (E.g. by paying off a DNA lab technician to certify the wrong result.) 

Often, gameable bottlenecks arise because a single metric or sign has been implemented based on previous reliability; however, the act of making this metric/sign authoritative actually changes how reliable it is. For instance, we can imagine that if, in a college admissions regime where an SAT score was only very small part of one's college admissions result, it might be one of the strongest predictors of applicants' academic success. That is because there was very little evaluative pressure being put on it, and "gaming" by applicants was relatively limited and infrequent. In other words, the low weighting of an SAT score on college admission decisions _helped make it a reliable signal_. 

If colleges began putting enormous weight on that same SAT score, all of the sudden, applicants would be highly incentivized to game their scores, be it through tutoring, paying test-takers, or other forms of cheating. Suddenly the measure would be less reliable. This is known as [[surrogation|Campbell's Law]], and is a kind of [[surrogation]] effect. Campbell 1976: 

> Achievement tests may well be valuable indicators of general school achievement under conditions of normal teaching aimed at general competence. But when test scores become the goal of the teaching process, they both lose their value as indicators of educational status and distort the educational process in undesirable ways. (Similar biases of course surround the use of objective tests in courses or as entrance examinations.)

A potential dishonest signaler, looking for his most effective deception strategy, ought to find signals that are perceived as uniquely reliable, or which hold uniquely authoritative weight, and bottleneck his own efforts into faking this signal. Long-term, given a steady environment, the game will work itself—the most reliable signals will be those which are hardest to fake, and the least reliable will be easiest. There will be a perfect correlation or equilibrium at-hand. Of course, in the real world, and especially in human domains where technological and sociocultural drift means the game environment is constantly changing, this will not be the case: certain once-reliable signals will be vestigially relied upon as authoritative, and these will be the optimal exploits for those who wish to deceive their evaluators. If evaluators wish to counter this bottleneck exploit, they should (1) employ a multitude of evaluative techniques, that are deployed either randomly or simultaneously (complementarily); (2) they should minimize transparency, so that the evaluated subject will not be able to focus his deception efforts to a single point of failure, and instead must spread his resources/optimize across many possible tests.

**TL;DR, highly reliable signals can become singularly authoritative in evaluative process, creating a "bottleneck" or single point of failure in adversarial expression games.**

Donath 2011 gives us a more human-centric understanding of signals:
> Many of the things we want to know about each other are not directly perceivable. These qualities include emotional states (are you happy?), innate abilities (are you smart?), and the likelihood of acting a particular way in the future (will you be a loyal friend?). Instead, we must rely upon signals, which are perceivable indicators of these not directly observable qualities.

And she makes almost no distinction between intentionally communicated information as signals, and unintentional expression (e.g. an accent as giving away where you're from—the lack of ability to selectively disclose this means it'll often be disadvantageous to the speaker, such as when visiting a foreign country and hoping to blend in or avoid scammers):
> We rely on signals when direct evaluation of the quality is too difficult or dangerous. [...] Saying “yes, I would like another helping of your special Tuna-Delight” can signal either hunger or politeness while the accent with which it is said can signal country of origin and social class. Indeed, much of our communication, whether it is with words, gestures, or displays of possessions, consists of signaling information about who we are and what we are thinking.

Her piece does do a good job of summarizing the symmetrical asymmetry of relationships, however, where it's in an observer's interest to know the "truth" of their observed subject, and in the observed's interest to put on the most advantageous appearance. (By symmetrically asymmetrical, I mean, there is an observed-->observer relationship, with conflicting or competing goals, and that relationship is mirrored in almost all interaction, e.g. the job interviewer is also being observed by the candidate to decide whether he wants to take the job, just as the interviewer is evaluating to decide whether to offer it).
> even within cooperative relationships there are elements of competition and conflicts of interest about plans and identity: I wish to present myself in the best possible light while you want to know what I am really thinking and what I really can and will do.

When it comes times to distinguish signals from cues, she avoids the complicated problem of intent vs consequence with an "either":
> We will use the term “cue” to refer to all the things we perceive that indicate some other hidden state or intention and we will reserve the word “signal” for those cues that **are meant to serve** as communication, **either because they have evolved for that purpose or because they are intentionally communicative.**

To define cues, she cites Maynard Smith and Harper: 
> "any feature of the world, animate or inanimate, that can be used … as a guide to future action" [...] Everything that we use to infer a hidden quality is a cue. A cue is a signal only if it is intended to provide that information.

Cues are a kind of "evidence"; we do not choose to emit CO2 _in order to guide a mosquito to us_, but it guides the mosquito all the same. "The purpose of a signal is communication and its goal is to alter the receiver’s beliefs or behavior." I dig—this echoes the line I like that [[all communication is manipulation]]—but I can't help but think she is continuing to dodge or ellide the key question here: what does it mean for a piece of information to have a _purpose_, or _intent_, or to be _meant_ for some end. If we can answer this, we can also perhaps answer important questions about the nature of a game's "spirit," since many of the relevant games are subject to the same evolutionary issues as cues. How can we define a purpose, or an intent, in an evolutionary system?

Dennett here might say bah humbug—animals _do_ have intents, there is a goal of their collective cells:
> Agents, in this carefully limited perspective, need not be conscious, need not understand, need not have minds, but they do need to be structured to exploit physical regularities that enable them to use information (following the laws of computation) to perform tasks, beginning with the fundamental task of self-preservation, which involves not just providing themselves with the energy needed to wield their tools, but the ability to adjust to their local environments in ways that advance their prospects.

> The other amazing thing that happens when cells connect their internal signalling networks is that the physiological setpoints that serve as primitive goals in cellular homeostatic loops, and the measurement processes that detect deviations from the correct range, are both scaled up. In large cell collectives, these are scaled massively in both space (to a tissue- or organ-scale) and time (larger memory and anticipation capabilities, because the combined network of many cells has hugely more computational capacity than the sum of individual cells’ abilities). This means that their goals – the physicochemical states that serve as attractors in their state space – are also scaled up from the tiny, physiological homeostatic goals of single cells to the much larger, anatomical homeostasis of regeneration and development.

I'm still left unsatisfied though, this kind of intentionally doesn't "click" into place w/r/t problems like "is X mutation that helps an organism by attracting pollinators _meant_ to attract pollinators," or, in the immortal lines of Van Morrison, "There's no why why why / It just is"—it just _does_ happen to help the organism, and that's all there is to it. In human terms, we might want to know that X helps accomplish goals, and then we can choose purposefully to keep doing it, _for the accomplishing of this goal_. But in evolutionary terms, behavior that helps an organism is just statistically more likely to reproduce itself.

Maybe our best heuristic for this problem is, _would the behavior still be performed_, or the _expression still exist_, if there was no receiver? 

> When a signal loses its audience – perhaps because it is too unreliable – eventually it ceases to be produced, since with no audience, it has no benefit. Non-signaling cues – such as the CO2 one emits – operate outside this system. Even if there are no mosquitoes around, we still give off carbon dioxide

My face’s mirroring of internal emotions like stress, anguish, or joy seems to occur regardless of whether others are present. But we can also imagine previous signals persevering in the gene code because there has not yet been adequate selection pressure to select them out.

A single stimulus, obviously, has _many_ meanings, a meaning relative to each receiver who observes and interprets it. Thus, a signal exists between a signaler and a _projected receiver_ or theoretical audience. It is an effort that we may call more or less successful if the received meaning more or less matches the intended meaning. (See [the rule of pragmatic reader-response](https://pfeilstorch.talkyard.net/-64).)

> A feature may function simultaneously as a signal and as an unintentional cue. One might intentionally display a signal for one receiver only to have it be picked up as evidence by another. One may dress in furs as a signal of success and wealth – but a robber may interpret this same clothing as evidence that waylaying the fur-wearer will net a hefty haul of fine jewelry. Or, the intended receiver may interpret a signal in unintended ways. The fur-wearer may intend to the signal wealth, taste and success to someone she hopes to impress, but that person may instead interpret the furs as evidence that she is cruel to animals.

> A feature may be evidence in one context and used as a signal in another. Wrinkled hands are usually evidence of old age, their appearance results from the loss of collagen, elastin and subcutaneous fat, not from any communicative purpose. Yet in situations where being old is advantageous, ranging from ticket booths that give senior citizen discounts in our otherwise youth obsessed society to cultures where old age is revered and respected, one might choose to show off gnarled and wrinkled hands, amplifying their appearance to signal advanced years. All cues, both signals and evidence, provide a means to infer some quality. Signals are meant to communicate the quality; their purpose is to alter the receiver’s beliefs or behaviors in ways that benefit the signaler. Unintentional cues, or evidence, exist for other reasons and they may provide information detrimental to the one who reveals them.

Another strategy for differentiating signals and cues is the context-sensitivity of the behavior. Following [Saleh et al 2007](https://link.springer.com/article/10.1007/s11829-007-9011-6), if a bumblebee leaves a certain scent marker everywhere he goes, without context-based discretion, it is almost certainly a cue. 

Finally, Hasson (1994) describes a cue as "any feature of the world, animate or inanimate, that can be used by an animal as a guide to future action" (Krebs & Davies 1997: "Behavioral Ecology: An Evolutionary Approach".

# Inter-specific vs intra-specific fitness

[[_Language in Thought and Action_]]:
> A great deal of evidence in modern biology indicates that those species that have developed elaborate means of intraspecific competition often make themselves unfit for interspecific competition, so that such species are either already extinct or are threatened with extinction at any time. The peacock's tail, although useful in sexual competition against other peacocks, is only a hindrance in coping with the environment or competing against other species. The peacock could therefore be wiped out overnight by a sudden change in ecological balance.

![[_Communication_]]