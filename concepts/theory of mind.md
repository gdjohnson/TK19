# Theory of mind in the predictive paradigm

Friston & Frith 2015:

> In communication and the interpretation of [[intent]], the very notion of _theory of mind_ speaks directly to inference, in the sense that theories make predictions that have to be tested against (sensory) data.

> Imagine two brains, each mandated to model the (external) states of the world causing sensory input. Now imagine that sensations can only be caused by (the action of one brain on the other. This means that the first brain has to model the second. However, the second brain is modeling the first, which means the first brain must have a model of the second brain, which includes a model of the first—and so on, _ad infinitum_. However, this infinite regress dissolves if each brain models the sensations caused by itself and the other as being generated in the same way. In other words, if there is a shared narrative or dynamic that both brains subscribe to, then they can predict each other exactly—at least for short periods of time.

(_Compare Rochat's_ Others In Mind.)

# Level K Theory

_See also entry on [[Reflexivity]]._

From Annie Duke's writings:

> Annie: I'm reraising to take the bluff away from Erik—at least, I'm supposed to be taking the bluff away—since it would be very difficult for me to be on a naked bluff for such a huge portion of my stack. Practically nobody would float my 3-bet with our stack sizes—but Erik fools me by calling a huge portion of his stack to execute a bluff later. He may be the only person who would actually make that play.
>
> Vanessa: I get it, but if you take it to the next level, a player as good as Erik can recognize that your raise is designed to take the bluff away from him. The size of your 3-bet on the flop gave him the perfect opportunity to set up a really big bluff. Good players are the ones you can run an elaborate bluff against because they'll make big laydowns—and Erik knows you're a really good player. So, even though you're representing a strong hand like top pair, he knows he can run you off of your hand on the turn because he’s representing something even stronger. In heads-up play, you rarely get a super strong hand like a set, so there aren't many opportunities to represent one with big bets and raises. In this hand, there have been enough bets and raises that Erik can actually pull off a big bluff by representing a really big hand such as a set. He knows that a big bet on the turn could be strong enough to get you to fold top pair. He knows that, even if you have K-Q or K-J, you would have a very hard time calling 160,000. And even if you call the bet on the turn, I don't think you could call another big bet if Erik were to ship on the river.

# Academian 2018: Unrolling social reality

Academian argues in this LessWrong post that the typical assumption of three pertinent social "levels" is wrong.

He gives the following example of a four-level-nested interaction:

> 1.1) Alex leaves out the milk for 5 minutes
> 
> 1.2) Bailey observes (1.1), and feels it was bad.
> 
> Unrolling of referents: Bailey felt that Alex leaving out the milk was bad.
> 
> 1.3) Alex observes (1.2), and feels judged.
> 
> Unrolling of referents: Alex felt that Bailey felt that Alex leaving out the milk was bad.
> 
> 1.4) Alex reflects on feeling judged, doesn't like it, and concludes that Bailey is "a downer".
> 
> Unrolling of referents: Alex felt it was bad that Alex felt that Bailey felt that Alex leaving out the milk was bad.

We can further imagine an onlooker, Charlie, believing that Alex's opinion of Bailey as a downer is, itself, "snobby"; Bailey might appreciate Charlie's defense, and think more highly of him. Already we are getting far away from some object-level grounding like "leaving the milk out."