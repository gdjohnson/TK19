_See also [[Strategic Interaction]]._

Austen calls the ability to see into the future, [[generalized reading|read individuals]], and act [[strategic interaction|strategically]] "penetration." In _The Count of Monte Cristo_, Dumas refers to a granite wall as being "as impenetrable as futurity."

# Kilcullen 2006: Twenty-eight articles

> [[trust]] is a function of reliability. Indeed, in local languages in many part of the world where we operate, the words for "honor" and "reliability" are similar or the same. Dependability is key—local people must believe that you will follow through and deliver on promises in a reliable manner. Over time, the predictability and order that you create through dependability makes people feel safer and encourages them to work with you.

# Yudkowsky: Efficient Cross-Domain Optimization

> Steering the future, not energy or mass, not food or bullets, is the raw currency of conflict and cooperation among agents.  Kasparov competed against Deep Blue to steer the chessboard into a region where he won - knights and bishops were only his pawns... this - computationally-frugal cross-domain future-steering - is the necessary and sufficient meaning that the wise should attach to the word, "intelligence"

# Yudkowsky: Aiming at the Target

> When I think you're a powerful intelligence, and I think I know something about your preferences, then I'll predict that you'll steer reality into regions that are higher in your preference ordering. Think of a huge circle containing all possible outcomes, such that outcomes higher in your preference ordering appear to be closer to the center.  Outcomes between which you are indifferent are the same distance from the center - imagine concentric rings of outcomes that are all equally preferred.  If you aim your actions and strike a consequence close to the center - an outcome that ranks high in your preference ordering - then I'll think better of your ability to aim.

# Reason 2020: Mutual modeling of futures

A lot of the work that human beings are up to is basically about self-representing future states. Schelling talks about what strategy is in _The Strategy of Conflict_: basically, it’s mutual anticipation. Because your actions (and your future actions) are going to change the environment in which my own decisions and actions exist. ([[a solution is indexical to its problem]].) That means that if I want to optimize my own future, then I need to anticipate yours.

Impression management, then, is basically projecting an image of your own patterns and intentions that will cause other players to behave in the way most beneficial to you. [[All communication is manipulation]]. 

He calls _tacit bargaining_ a situation where two sides with some conflicting and some mutual interests are playing a variable sum game and they act on the basis of what they think the order party is going to do, which is in turn influenced by what the other party does, and so on recursively. A classic example is Rock-Paper-Scissors:

> I played rock last move, so they know I know I’m not going to play rock again, because I lost last turn. So they know not to use paper. They’re going to play either rock or scissors. And then, obviously, if that’s a common pattern, I’m going to think about how you might be thinking that’s the strategy I’ll take, etc. 

This is commonplace in everyday [[strategic interaction|strategy games]], it’s basically just [[predictive processing]] meets [[theory of mind]].

Say person A and person B are walking down the sidewalk in opposite directions, approaching each other on a narrow path. They’re definitely going run into each other soon if they keep walking forward. One strategy is to “perform obliviousness”, as [[Kenneth Liberman]] calls it. You basically act as if you don’t know or care I’m there, you’re not changing course. If person A is performing obliviousness, then person B can say “You know what, I know what your path is. Let me just slip to the side and then we’re both fine, we won’t run into each other.” But as soon as you get into the more recursive modeling, e.g. Person A looks at Person B while they’re still thinking and thinks: “Wait, is Person B also performing obliviousness?” and decides to be more reactive, then you end-up in this weird side-to-side shuffle. For instance, you’re ten yards apart, you’re both going back and forth horizontally,  getting in each others’ way. It’s in both your interests to get out of each others’s way, but it’s in each of your interest to not move or to move the least. Lots of reasons that might be—laziness, energy expenditure minimization, or even status games.

What this comes down to is that Person A, who’s performing obliviousness, is broadcasting a self-representation of a future state. Doing this allows other agents to organize around them, to coordinate more effectively.

A similar example is playing “Chicken”. Let’s say you’re driving towards another car, betting on who’s going to turn away first. If you throw your steering wheel out the window or spray paint over your windshield in advance, there is no way to steer or react in time, respectively. You’ve self-bound to a course of action. Your opponent no longer has a choice, if they don’t turn away, the two cars will crash. You know that your opponent is a rational agent, or at least rational enough to want to live. So you’ve won. Your opponent has to get out of the way, because they know for a fact that you won’t. It’s better for them to lose face then run into you and die. You’ve established a single Schelling point, a single outcome the system will coordinate to if no further communication or changes can take place.

I create this self-representation, I broadcast it, and then we optimize around a shared future reality that I’ve created. Problems emerge because humans can represent one way and act another way. There’s nothing inherently binding about language. I think that’s really interesting—it’s what [[opticratics]] and self-deception is all about. 

When you throw your steering wheel out the window, you’ve self-bound. There’s a physical limitation on what you can do now. If the other person driving towards you can see that self-binding of futures then they know you just can’t make another decision, even if it would rational, even if it would be better for you to get out of the way at the very last second. You can’t make the decision anymore. You’ve said: I win or bust.

You’re essentially making a tradeoff: I’m going to sacrifice some still good, but not quite optimal futures, like veering away first in the game of Chicken. I’m going to throw my steering wheel out the window and sacrifice these not-bad futures, for the _most_ optimal future: the one where I win and don’t die. You can put all your eggs in one basket, put all your resources into achieving the optimal outcome. But problems emerge: you can represent things one way,  but act in another. Consider the theatrical effect of throwing out a dummy steering wheel and making sure the real one wasn’t visible through a heavily tinted windshield.

Schelling talks about how different it would be if you had a society where you could linguistically invoke an oath, e.g. to God. (The problem with language, more or less, is that it isn't binding except in institutional situations of surveillance and preferential reward/punishment.) Imagine a society full of perfectly rational, hell-fearing individuals. Invoking an oath to God is perfectly binding because nothing is worse than an eternity of damnation. In such a society there’d be no such thing as boring. I’d say “I swear to God, I won’t pay more than $16k for this car.” Now the salesman can take it or leave it. Normally, there’s a whole range. Let’s say the car costs the salesman $12k wholesale. Let’s say it’s worth $20k to me. So any sale between $12k and $20k is going to be mutually beneficial—kind of like getting out of the way in Chicken. It’s a positive sum game, so it’s better to negotiate than stalemate. A stalemate here would mean the seller doesn’t make any money and I don’t get a car. 

Schelling talks about how conflict is not just about conflicting interests, they have a whole base of mutual interests and then _some_ conflicting interests. Other than wars of total annihilation, there’s no such thing as pure conflict.  In this case it’s clear: the seller wants money and the buyer (me), wants a car. For anything between $12k and $20k there’s mutual interest, but the settling point of the negotiation has a lot to do with bargaining power. If one party considers the other rational, then they have to somehow convince the other party that they won’t go lower or higher. If the seller thinks they’re dealing with a rational buyer, who’s interest it is to buy at $12k, then the seller has to somehow convince the buyer that he won’t go that low. The buyer has to show that he won’t buy at $20k even though it’s still in his interests, in order to get the best deal possible. In essence, you’re approximating the swear-on-God technology that would allow you demonstrate you won’t buy at a given price.

This makes me think about  Blockchain, because Blockchain smart contracts are a form of self-binding.  Without Blockchain, though, I can still go to a 3rd-party and say “Hey, if I pay more than $16k for the car, then I’m going to owe **you** $10k.” and sign a formal legal document to this effect. You bring a copy of your little legal agreement to the car seller, with the proper documentation to confirm its legal authority. Now the seller has to basically take $16k or leave it.  (Note that we’re assuming there aren’t any other buyers in this ideal situation.) Basically, the seller is going to take the $16k unless he’s got _more_ than $16k worth of spite, because he has perfect evidence that you’re not going to go higher than that. (If he’s got more than $16k worth of spite he’ll tell you to fuck-off with your fancy third-party leveraging strategies.) 

I think a lot of human behavior comes down to this self-legibilizing process. The way you dress, the way you behave, the patterns of conversation you engage in all assert this. We think of manipulation as distorting someone’s priors so they’ll act a certain way. You could also distort their values, but values are harder to budge than priors in general. Values often exist independent of facts and are usually ingrained. It’s much easier to say “You thought these guys were the good guys, but they screwed you over, and I’m going to exploit your already-existing belief in Justice.” The general background notion of justice we often lay-claim to is likely just biological priors that were selected for certain kinds of cooperation.

A lot of manipulation happens by distorting someone’s impression of you. An impression is just a sense of how someone is going to behave. If you have a sense of how someone else is going to behave, then you can say, “You know what, I can behave this way, which has consequence X for the other party, because I know they’re not going to  get too mad at me. Or they’re not going to burn the bridge. Or they’re going to be fair about it if I present them with this problem.”  For example, if you know how mad a landlord will get with you for a breaking a certain rule, that influences if (or how often) you might choose to break it. 

We constantly want to do things that rely on predicting the behaviors of others. I want to know that you’re going to wire me back this money, because you really are an exotic prince who just happens to be in a really bad situation. That’s a dramatic example, but the world is full of examples where manipulation matters: our sidewalk example from earlier, negotiating salaries, or even micro-behaviors like doing the dishes. You do the dishes because you think it’ll strain the relationship between you and your roommate if you don’t. If your roommate gets upset regularly then their actions create a model in your head of how they’re going to act that can be strategically deployed. Knowing that in the future your roommate is going to get mad if you don’t do the dishes means it’s now in your interest to do the dishes, or that you can use them as payback if revenge is what you’re after.

Human beings communicate & coordinate by self-legibilizing. The self-representation of properties that are predictive of the future is key to stabilizing this dynamic (and often recursive) mutual-modeling process, which is the essence of social dynamics.

![[_The Social Construction of Reality_#Typification and mutual prediction]]