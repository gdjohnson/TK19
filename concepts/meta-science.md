---
aliases: philosophy of science
---

# Gatekeeping

Siler, Lee, & Bero 2014, "Measuring the effectiveness of scientific gatekeeping" broadly confirms the intuition that peer review acts as a bandpass filter, effectively filtering out poor submissions while also rejecting ones of exceptional quality. In other words, crackpots can be tough to tell from geniuses, as Kenny Easwaran [highlights](www.kennyeaswaran.org/teaching/2017-fall/phil351fall17).

# Misconduct

Edwards & Roy 2016: "Maintaining Scientific Integrity in a Climate of Perverse Incentives and Hypercompetition":

> Specifically, if rewards are disproportionally given to individuals manipulating their metrics, problems of the old subjective paradigms (e.g., old-boys' networks) may be tame by comparison. In a 2010 survey, 71% of respondents stated that they feared colleagues can "game" or "cheat" their way into better evaluations at their institutions.

> Recent exposés have revealed schemes by journals to manipulate impact factors, use of p-hacking by researchers to mine for statistically significant and publishable results, rigging of the peer-review process itself, and overcitation (Falagas and Alexiou, 2008; Labbé, 2010; Zhivotovsky and Krutovsky, 2008; Bartneck and Kokkelmans, 2011; Delgado López-Cózar et al., 2012; McDermott, 2013; Van Noorden, 2014; Barry, 2015). A fictional character was recently created to demonstrate a “spamming war in the heart of science,” by generation of 102 fake articles and a stellar h-index of 94 on Google Scholar (Labbé, 2010). Blogs describing how to more discretely raise h-index without committing outright fraud are also commonplace (e.g., Dem, 2011).

> A comprehensive meta-analysis of research misconduct surveys between 1987 and 2008 indicated that 1 in 50 scientists admitted to committing misconduct (fabrication, falsification, and/or modifying data) at least once and 14% knew of colleagues who had done so (Fanelli, 2009).

> up to 34% of researchers self-reported that they have engaged in “questionable research practices,” including “dropping data points on a gut feeling” and “changing the design, methodology, and results of a study in response to pressures from a funding source,” whereas up to 72% of those surveyed knew of colleagues who had done so (Fanelli, 2009). One study included in Fanelli's meta-analysis looked at rates of exposure to misconduct for 2,000 doctoral students and 2,000 faculty from the 99 largest graduate departments of chemistry, civil engineering, microbiology, and sociology, and found between 6 and 8% of both students and faculty had direct knowledge of faculty falsifying data (Swazey et al., 1993).

> In life science and biomedical research, the percentage of scientific articles retracted has increased 10-fold since 1975, and 67% were due to misconduct (Fang et al., 2012). Various hypotheses are proposed for this increase, including “lure of the luxury journal,” “pathological publishing,” prevalent misconduct policies, academic culture, career stage, and perverse incentives (Martinson et al., 2009; Harding et al., 2012; Laduke, 2013; Schekman, 2013; Buela-Casal, 2014; Fanelli et al., 2015; Marcus and Oransky, 2015; Sarewitz, 2016). Nature recently declared that “pretending research misconduct does not happen is no longer an option” (Nature, 2015).

> Academia and science are expected to be self-policing and self-correcting. However, based on our experiences, we believe there are incentives throughout the system that induce all stakeholders to “pretend misconduct does not happen.” Science has never developed a clear system for reporting, investigating, or dealing with allegations of research misconduct, and those individuals who do attempt to police behavior are likely to be frustrated and suffer severe negative professional repercussions (Macilwain, 1997; Kevles, 2000; Denworth, 2008). Academics largely operate on an unenforceable and unwritten honor system, in relation to what is considered fair in reporting research, grant writing practices, and “selling” research ideas, and there is serious doubt as to whether science as a whole can actually be considered self-correcting (Stroebe et al., 2012). 