From Benedict_SC's "Cordyceps: Too Clever For Their Own Good":
> “I'm sorry,” she said through gritted teeth. “I know this... is confusing for you. It's not that I don't trust you. But I can't tell you, and I can't tell you why I can't tell you.”
> “That sounds like... you either think I'm stupid, or your idea of 'the right thing' is different.”

## Noble lies

In the philosophical literature, interventions-on-behalf are typically advocated for under the name "noble lies." In such situations, the self-determination of the individual is sacrificed for his (or his society’s) benefit—or rather, for the ruling class’s conception of what is and is not to his benefit.

Eric Weinstein:
> Some ask why I support “load bearing” & “adult-level” fictions over the truth & request examples. Here’s one: it’s likely structurally important that Supreme Court Justices continue performing in costume to suggest they’re spiritually superior druids of unfathomable legal genius.

## Extrapolated vision

To Yudkowsky, interventionism is the problem of extrapolated vision. A friendly artificial intelligence would not merely fulfill our literal requests (think the classic genie fable, the way he grants a wish on technicality, while giving the asker the opposite of her desire). Rather, the AI should offer an _interpretive_ fulfillment of the asker’s volition, what the AI believes they actually want. 

The problem, of course, is coming up with a coherent, calibrated model of a person (or group’s) volition. Serving the master’s desires _even when he does not know he wants it_, or even when he has explicitly asked otherwise, is the very mark of the elite butler, or house servant, at least if you believe period films.

## Fiction

