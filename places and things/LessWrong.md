# Chalmers on LessWrong

**[davidchalmers](https://www.reddit.com/user/davidchalmers/)**

**David Chalmers**

[3 years ago](https://www.reddit.com/r/philosophy/comments/5vji57/im_david_chalmers_philosopher_interested_in/de2jklb/)

[/u/willbell](https://www.reddit.com/u/willbell/) asked:

> Holy crap it's you. What do you see in Less Wrong? They seem very intent on replacing areas of philosophy with non-critical versions of those areas (e.g. [[aesthetics]] -> neuroaesthetics, as if those are asking the same questions, etc) so I find them hard to take seriously, yet you seem to.I never really got the p-zombie argument, you use it as an argument for non-physicalism but how is it that you move from 'p-zombies are conceivable' to 'mind and brain are actually distinct in a non-physicalist way'? Why couldn't the further fact in which we differ from a world of p-zombies be certain facts about how metaphysical emergence works rather than some sort of psychological stuff? What is the best argument against non-reductive physicalism in your opinion? At any point when you had longer hair, did you ever consider quitting philosophy and starting a rock and roll band?

i don't know about the less wrong blog specifically (it seems to be moribund these days), but i've seen a lot of interesting ideas come from the "rationalist" community of which it has been a focal point. the most obvious is **the issue of AI safety in the context of superintelligence, which has become a huge issue both inside and outside academia, and for which the main credit has to go jointly to nick bostrom (who's an academic philosopher but also connected to that community) and eliezer yudkowsky** (who's a nonacademic philosopher who founded the less wrong blog and has been at the center of that community), who explored the issues for years before the world was paying much attention. **there was also a very interesting proto-decision-theory (timeless or updateless decision theory) developed a few years by eliezer and others at less wrong**, though i've been disappointed that no one has been able to give a well-developed clear and rigorous statement of the theory since then. i also like very much the idea of "applied rationality" that was a focus on less wrong and for the center for applied rationality, which grew out of this community. it's surprising that although there's a huge amount of applied ethics in philosophy, **there's not very much applied epistemology, and i give the rationalist community credit for developing that approach**. finally, **the whole effective altruism movement is at least loosely connected to this community (though it was started in large part by academic philosophers)**, and i think a lot that's of both philosophical and practical value has come out of that.

of course as with most communities, this one has its own idiosyncracies and pathologies. **many ideas put forward are oversimplistic or reinvent wheels**, and it hasn't helped that ideas have often been circulated in half-baked forms on blogs or in the oral tradition. and of course **some rationalists make wildly ambitious claims about solving or dissolving traditional philosophical problems. but the same is true for the logical positivists in the 1920s and 1930s**, who the rationalist community resemble in a number of respects (except that **rationalists' positivism focuses on reducing problems to questions about algorithms rather than to questions about experience**). the logical positivists were oversimplistic in many respects and made many mistakes, and they turned out not to solve or dissolve the deepest traditional problems, but they nevertheless did some very important philosophy. as i mention in another reply, i think **having subcommunities of this sort that make their own distinctive assumptions is an important mechanism of philosophical priogress**. to use your example, even if neuroaesthetics can't solve all the traditional problems of [[aesthetics]] (as i'm sure it can't), maybe the attempt will lead to interesting related ideas that help solve related problems. so **i'm all in favor of having subcultures like this that generate interesting ideas so we can see where they go. maybe they'll have some bad ideas along the way, but those are easy to weed out. it's a small price to pay for generating new good ideas.**

# Jen RM on Singularity and Yudkowsky

**jenrm**

Something I wonder about, is what would have happened if Google/Kurzweil hadn't given Eliezer $1M-ish in 2012 to give them de facto ownership of the word "singularity."

**Suspended Reason**

[@](https://ust-sloths.slack.com/team/U3DTJBY1M)jenrm say more? I don't know anything about this, but you're correct that in philosophical communities, Yudkowsky & Bostrom seem like the owners of singularity these days

**jenrm**

So. Vernor Vinge coined the term "singularity" in like 1992. Then young-foolish-honest-in-public Eli made Singularitarianism his ritualistic tribe in like 2000 and started an organization with the word in the title.

So while in Europe they might argue that Vinge has inalienable artistic rights to the concept, in the US a trade mark court would side with Eliezer. Then Kurzweil swooped in with better tactics and marketing to make money off the fad, re-purposing the Nth iteration of "the age of <adjective> machines" book series into something with Singularity in the title, and starting a for-profit business incubator that charges tuition called Singularity University.

SIAI was constantly being confused with SU in the press.

One group had brains and enthusiasm and cultural mojo, but no money. The other was a bunch of corporate whores with money but no enthusiasm, so the whores paid the enthusiasts to stop using the word "singularity" and began to suck the money out of that brand in earnest, and the enthusiasts pivoted to hiring mathematicians and retreating from the world in a swirl of harry potter references and sex scandals. 

Then blockchain made a large number of a[ur]tists quite rich, and so MIRI (the thing people call SIAI nowadays) is, I think, decently funded and focused mostly on doing math research. Mostly at this point I think they regret having made such a big splash in the mental models of the world, because it would be easier to write up the algorithms that god should run on in peace and quiet, than to write such software while also having to constantly do damage control when crazy people become obsessed with them, and talk about them, and generally make it hard to be properly a[ur]tistic.

I guess I should point out that all of this could restated in a way that shows respect and appreciation for "enthusiasm" and "making money" and so on. It is just easier to summarize key points with an air of weary disrespect.

# Simon DeDeo: Devs, Oracles, and the Alpha Female

> In an essay for FQXi’s prize competition this year, I defined [computerland](https://fqxi.org/community/forum/topic/3492) as the pair of claims that (1) we, and our societies, are computers; (2) physical reality itself is a computer simulation (or might as well be).
> 
> Computerland takes these and makes an ideological and total account of what the world might, at heart, really be about. In that sense it’s no different from Marxism, and it may end up as the first truly novel mass ideology of the 21st Century. The analogy is more than just a burn, because it helps us get a grip on exactly what is going on.
> 
> Just as Marxism had its geneaology, for example, so does Computerland: Computerland’s Hegel is Douglas Hofstader, and its *Phenomenology of Spirit* is *Gödel, Escher, Bach*. The profs might still be Marxists, but most elite universities in the United States have at least one student group devoted to the computerland ideology, or an offshoot like Effective Altruism. That’s in part because Computerland has things like [The Sequences](https://wiki.lesswrong.com/wiki/Sequences). (David Deutsch in this parable is Trotsky, and his atavistic commitment to liberal democracy is going to put him on a flight to Mexico City.)
> 
> Computerland—as both a metaphysics, and a political theory—is philosophically interesting. It’s also psychologically interesting because you want to know what happens when people sign on for real. While there are a few doctrinaire Computerlanders, there are far more people for whom computerland is just a place they’ve grown up in, partly by chance and partly by choice. Now, computerland’s chunk of California controls a far larger fraction of the world’s resources than the Soviet Union ever did.
> 
> Even computerland’s heretics are influential, because they speak the language even as they reject it: Mencius Moldbug and the NRx, for example. Because computerland is allied against the reining orthodoxy on the East Coast, it’s still a bit difficult to talk about, but as that latter system continues to decline, I expect it to continue to grow. I imagine it circulates in the more metaphysical reaches of the Party in the People’s Republic of China.
> 
> Unlike Doug, who hates the whole thing, my feelings about computerland are mixed. It’s nice that, contrary to Fukuyama, the history of spirit did not end with John Rawls. As a way of looking at the world it’s fruitful, and I would not want to live in a world without computerland’s ideas any more than one without Marx or Freud. I’m completely pro computerland reading groups, just as I am completely pro *Das Kapital* reading groups. One of the many good features of computerland is it actually contains the seeds of its own destruction: the underlying theories are really about what is not computable.
> 
> Of course, Marx hypothesised the withering away of the State, too, but that never made it into actually existing Communism. As a way of understanding the world in a totalizing theory, computerland is a dead end, which means that if you stay there too long you are in danger of aestheticizing it. That can mean dabbling in American-style fascism—the Moldbug path, best depicted in the New York of [Man in the High Castle](https://en.wikipedia.org/wiki/The_Man_in_the_High_Castle_(TV_series)), with high technology, social order, old-style sex roles (except for the Lebensborn), and eugenics. Or utopianism—updated versions of Seasteading, Galt’s Gulch, or the Concents of *Anathem*. That’s a bit like [getting so in to the Plato’s *Republic* you recreate a Greek city state](https://amzn.to/3eIpiyp). In the end, it stops you from doing truly wonderful things—but it’s hard for people to escape, because it’s more than a set of ideas; it’s a mythology.

# Advantageous conditions for LessWrong's epistemologies

_See also [[Blogging]]._

## Ideological

Concepts that Yudkowsky & LessWrong had to "start" with:

- Map & the territory
- Bayesian inference
- Prototype theory/[[fuzzy]] concepts
- Computer science, SQL databases, & neural nets
- A well-understood tradition of pragmatism
- Cognitive bias & a distrust of intuitions
- A lack of conceptual analysis, which is cited by Muehlhauser & Yudkowsky as one of mainstream philosophy's "bad habits of thought"

### Skepticism toward Intuitions

See interest in cognitive biases more generally.

from the SEP entry "[Concepts](https://plato.stanford.edu/entries/concepts/#ConAto)":

In a preliminary study of East Asian vs. Western intuitions, Jonathan Weinberg, Shaun Nichols, & Stephen Stich (2001) found that East Asians often have the “wrong intuitions” regarding variations on classic philosophical thought experiments, including Gettier-type thought experiments (though see Machery et al 2017 for evidence that some of these intuitions may in fact be universal)

### Map & Territory

Why is this metaphor so useful, and what can ethnomethodological understandings of map-reading bring to the conversation? What does it mean for a map to be "true" or "false," to have information that is "all map," or for features of a territory to be vague or uncharted?

- [Liberman on "Sketched Maps"](https://play.google.com/books/reader?id=9XWEJQAAAEAJ&pg=GBS.PA17)
- [Brown & Laurier on EM & Maps](https://sci-hub.tw/10.3138/6QPX-0V10-24R0-0621)

#### Criticisms of the Map Metaphor

@Meaningness
Current framing: the representation/reality relationship is the CENTRAL and unsolvable problem for rationalism. Maps are highly atypical representations: the relationship is much simpler than most.

LW uses “map” instead of “representation” in order make it seem like the relationship is straightforward *in general*. That hides the central problem on which the whole story founders.
David Chapman

I think this is semi-deliberate: they found that thinking in terms of “maps” instead of “representations” clarified their thinking considerably, so they went with it.

Indeed, it does make the story much more precise & tractable, at the cost of making it much more wrong.

The essay undermines this by pointing out the even literal maps don’t work anything like the way LW uses the word. There’s tons of nebulosity in there, not just uncertainty or imprecision. (But less nebulosity than with most representations)

@JakeOrthwein

Maybe this idea about “entanglement” and “mutual information” could focus the criticism a bit? This seems to underpin Yudkowsky’s general conception of representation.

@Meaningness

I don’t think he has a coherent theory. He’s got a swirl of bits of theory-stuff he picked up from reading cogsci unsystematically, and hasn’t realized they are mutually contradictory and can’t be assembled into a workable overall account.

The point (of my piece) is not to criticize EY, who I don’t consider significant, but the map/territory metaphor, which is much more widespread than LWism. This bit isn’t about maps, so it’s not relevant to this particular essay.

## Structural

### Selection

See Bertrand Russell's quote on philosophers (cited in Muehlhauser 2013: Train Philosophers with Pearl and Kahneman, not Plato and Kant): "Hitherto the people attracted to philosophy have been mostly those who loved the big generalizations, which were all wrong, so that few people with exact minds have taken up the subject."

Specialization, moreover, occurs on self-selection, such that experts in a field become the people who believe it is most important. Thus "experts" in philosophy of religion are also themselves overwhelmingly theistic; their choice to study philosophy of religion is almost certainly a consequence of their theism. Those in metaphysics are inclined to certain positions about the nature of reality *simply because they did not choose instead to go into epistemology*. As Carl Schulman [writes](https://www.lesswrong.com/posts/Nm8W6FShTJEMoczix/what-do-professional-philosophers-believe-and-why?commentId=fayQYA3RjK2TLHJFM) in a LW comment section, moral anti-realists won't go into meta-ethics. And as Dan Davis points out, there is not just selection but evolutionary bias: "People who assert that a field is worthwhile are more likely to be successful in that field."

# Mottos

_The map is not the territory._

_Pain is not the unit of effort._

_Money is a (if not the) unit of caring._

# Potato on LessWrong vs Analytic

LW user *potato* posts (c. 2012) a personal experience in philosophy graduate departments, where he claims to have had prior commitments to academic-analytic philosophy which were disrupted by discovering that "this blog of college kids" have managed to solve otherwise difficult problems with relatively little training. The impetus of his post is to test this belief by prompting LW'ers to attempt, in future posts, solutions to a set of unsolved philosophical problems, and see if they can get traction on them. Unfortunately, he never follows up on this plan.

> By and large, I would bet money that the devoted, experienced, and properly sequenced LWer, is a better philosopher than the average current philosophy majors concentrating in the analytic tradition... I have always thought of myself as an aspiring analytic philosopher, and even got attached to the ascetics of analytic philosophy. I thought of analytic philosophy as the new science of philosophy that finally got it right. It bothered me to no end that I had been lead to have more faith in the philosophical maturity/competence of a bunch of amateurs on a blog, than in the experts and students of the field that I planned to spend the rest of my life on. I have committed myself to the methods of academic-analytic philosophy publicly in speeches and to my closest friends, colleagues, and family; to turn around in under a year and say that that was all naive enthusiasm, and that there's this blog of college kids that do it better, made me look very stupid in more than one eye, I cared and care about.

There is a [brief response by Seth Kurtenbach](https://web.archive.org/web/20161022184332/http://musasha.wordpress.com/2011/11/29/analytic-philosophy/), an analytic PhD out of UMissouri, but Kurtenbach is broadly unfamiliar with LessWrong, and merely (but fairly) contends with the sloppy, "circlejerk" (his word) argument of OP. Does not unfortunately deal with the substance of the claim.

# LessWrong and Postmodernism

While most rationalists consider themselves explicitly in opposition to postmodern thought, I will argue that their frame is actually highly compatible with many, though certainly not all, of the movement’s ideas.

The core components to this argument: that there are, in the philosophical tradition, relativists and objectivists. The distinction is one of mind-dependence vs. mind-independence. In ancient Athens, this conflict played out between the Sophists, led by Protagoras, and the Platonists, led by Plato. Protagoras—an agnostic, who wrote that he had “no means of knowing whether [the Gods] exist or not, or of what sort they may be—appears to have understood (the historical record is spotty) concepts such as the pleasurable, the moral, the beautiful, and the just as dependent on individuals’ frames or criteria, which are themselves strongly cultural. Plato, meanwhile, believes that the form of objects (such as, infamously, a table) meaningfully exist; he and many of his philosophical contemporaries worried about the effect on Athenian society that Sophist beliefs in relativism may have had, and thus worked hard to formulate concepts just as justice and beauty as if they had objective, knowable attributes (as opposed to cultural ones). Unfortunately, in the Western tradition, platonism won out—likely in significant part because of its theological adaptations in early Christian theology. Thus the conflict between objectivists and relativists has always been, to some extent, a conflict between magical worldviews and non-magical ones; it is not incidental that Plato is not an agnostic himself, advancing reasoning in defense of the gods’ existence, while Protagoras is.

Thus, while there may be many disagreements, over the history of relativist thought, as to which sorts of things are relative, vs. appearing to be hard-coded into the material world, the general paradigm of evaluating human concepts and categories as human-contingent belongs to this relativist tradition, of which Yudkowsky and the LessWrong rationalists are a part. While Yudkowsky may have opposition to cultural relativism as commonly practiced—much like the Sophists, cultural relativists have seen their ideology distorted & simplified to meet the needs of its advocates—it is my understanding that even his utilitarianism he would cast as one definition of morality among many, the definition which seems to best map what *matters* to human beings (as opposed to what is morally “true,” a frame he would vehemently reject in any objective, realist sense). Similarly, he would grant that the specific prescriptions or cultural norms which bring about these utilitarian ends at any given moment are highly contingent on cultural and historical context, though there may be Pareto frontiers. This alongside his blend of conceptual relativism and pragmatism—e.g. there is no “fact” about what the concept of “fair” means (see “[The Bedrock of Fairness](https://www.lesswrong.com/posts/iAxkfiyG8WizPSPbq/the-bedrock-of-fairness)”) and conceptual or linguistic distinctions are only meaningful insofar as they “pay rent,”—are consistently advocated in “A Human’s Guide to Words.”