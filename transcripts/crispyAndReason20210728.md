---
alias: unit of survival, unit of desire, unit of goal
---

# “Units of Survival”: Call Notes

Why do frames like “selection games” or “four styles of play” matter?

-   We need the language to talk about it. We need references to agree upon so we can coordinate around them, subject them to [[evolutionary epistemology]].
-   Language is rife with metaphors, this is not an accident and cannot be rooted out—we traffic in references to describe things, and we need good references.
-   “Can we prove reality is a game or not?” is a bad question. “Does our vocabulary for games allow us to explain things we already know and describe natural extensions that can then be tested?” is a good question.
    
Attractor states, aka stationary distributions: there are locations in the machine that a system ends up falling into, being unable to escape from. Attractor states (in Language Models) have not been rigorously proved to the NLP community; repetition loops “we” (Crispy + colleagues) have proved. 

Markov models (“Markovian things”) are those in which a node in a chain of nodes is conditioned on/affected by its immediate parent and only affects its child nodes. (i.e., cause + effect’s before + after.) See [[Markov blankets]].

Crispy: “A lot of men think that women look cute when they pout. I’ve seen a lot of individual women learn to pout when they’re trying to smooth over a conflict, b/c the men they’re with find them cute.” Once someone discovers the marker/criteria you’re using, they’ll manipulate it to get what they want ([[selection#Selection games]]). Viruses are that for cells, because all cells sequence RNA, and viruses are just carriers for RNA that end up getting sequenced. (Look into to understand process more fully.)

Hinge Premium + iterated [[selection|selection games]]: “Men who have more money will end up having more contact with pretty women.” The fact that this status [[games|game]] has been instantiated in the dating app tells you a status game that’s already happening in real life. (Imagine men paying to have less contact. Now imagine women paying to have less contact.)

It’s certainly true that new [[games]] are created within apps, but it is rare that apps can actually design these games, rather than facilitating the extension of old games into new ones.

Iterated [[selection|selection games]] (as true of single bars as dating apps?):

1.  The cream of the crop women are being selected out in advance, so they are entering the candidate pool (The men asking these women out are in competition with the dating apps.)
2.  Not enough deterrents to false advertising—if date goes south, there’s no fallout. (Hinge and OKCupid have combatted this with post-date surveys.)
3.  But also—couples come to bars, and people (often men) try to date already taken people (often women), so real life is more “dense”

General principles of this game: [Lvl 1] you have a pool that has good things selected out of it, the pool candidates want to be selected out of it, [Lvl 2] Matching games, some recirculation where those coupled up can be recoupled.

Selection games with sound—headphones, microphones, all about bleeding—who hears—all about [[boundaries]]. See gather.town, the way you enter a “table” or area and the video flips on. When you leave the area w/ your avatar, it flips off.

“The app that’s designed to be deleted.” (Hinge—anticipating and combating your fears that their selection incentives aren’t aligned w/yours.) Marketing/PR is applied psychology or psychological [[engineering]].

What do I need/want, to answer the challenge that signaling in cells vs humans vs institutions only has a “metaphorical” connection? I need a unit of goals and a unit of decision.

Crispy’s basic rebuttal to the idea of goals, is that you can’t really figure out what is optimizing for what. We could invent some test, and then receive all these lukewarm results for different possible optimizations and where would that leave us?

Or not: Goal argument may have to be founded in survival. If things didn’t have survival as a goal, they wouldn’t exist anymore.

So: A unit of survival.

Goal argument = intent argument. When a Congressional body passes a set of words… [[Language and law]]. What is the “goal” or “intent” of a government

If Y outcome only happens, or is only likely to happen given X intentionality of a superorganism, then we can attribute X intentionality to that superorganism. “The US hasn’t been invaded” tells us about the US’s goals.

I want it noted that this is a historical argument—we don’t know it until we’ve seen that the US consistently managed to avoid something that would have happened if one took a “random walk” through history where the US didn’t give a shit if it was invaded.

“Intent” as a concept is less about X and more about the Z’s that want to optimize around X in the future. Intent is pragmatic. A man on the street cares about whether someone is going to mug him, not whether the mugger “knows” it consciously or unconsciously.

The brain’s “intent” insofar as it’s a singular desire doesn’t exist, it’s more like a government of sub organisms with individual survival oriented goals. Crispy is a materialist of personhood: patterns of particles moving around at the bottom, whose patterns have gotten increasingly complex scaling up. “Me,” “desire” is just an abstraction. Kingdoms and feudalism, peasants as a model for selfhood. Does singular intent only exist at the subcellular level?

 “The self is the meme that won everything.”

(And there’s no reason to say bacteria aren’t “us”; there’s just the fact they aren’t our DNA… If they guide our decisions in the cellular “congress” that steers us, if they are inside our boundaries and invested in preserving those boundaries, why aren’t they us? Why aren’t they me?) They are me.

Selection games: when the Queen rides through town, her people are gonna advertise to her, she can’t get good data. The peasants can’t get good info because the royalty is influenced to spread wrong gossip. We would need strong cultural and literal technologies to make people honestly signal from a distance. That is, tech to constrain what they can “say” / present and get away with. 

[[Opticratics]]: “Honesty is the best policy” is strongly contingent on strong cultural technologies for monitoring. (The monitoring constrains, so your self-presentation has to be ballpark with what a third-party observer would witness/tell from monitoring tech.) It is highly socially and culturally indexical, e.g. if you are in a small community that is constantly ecologically huddled such that everyone is monitoring everyone else always. The more distant, and less huddled or ecologically proximate, individuals are, the less monitoring capacity. (The more costly it is to monitor.) Monitoring makes it costlier to lie, b/c you then must actively change your behavior to match the lie whenever you are witnessed, in whatever ways (cues, sensory channels) are monitored.

[[a heuristic is necessarily scoped to the distribution it’s optimized over]]

Further, actually monitoring everything is impossible, because the monitors end-up being biased and framed to do certain things. An infinite regress of monitors is not possible, because the universe is finite.

Unit of survival (our parochial “superorganism”): Something we recognize sensorily or phenomenally as discrete (United States, “Crispy”)—having a name is a good clue—because its boundaries would not have been maintained except by negative feedback of the collective itself. If sensorily it has boundaries that persevere over time and manipulation—it probably has to have sub-organisms making that happen.  (If someone tries to puncture a Markov blanket, you need to push back—negative feedback = resistance.) Crispy: “This is a historical argument—we don’t know when something has negative feedback; we know they’re there, or without them, the superorganism wouldn’t have maintained over time with these conditions. If I poke a hole in a rock, it’s fine. If you poke a hole in me, or a cell, it’s game over.” 

Our language is very teleological: “The ball wants to bounce back.” Our definition of survival is observational not empirically/testably, but HISTORICALLY. The history of a superorganism tells us what it is and what it wants. (And if it’s even a superorganism.)  

Even when we talk about things we consider mechanical, we often use intent to describe things. “I’m holding the ball in my hand, but it wants to drop to the ground because of gravity.” This is not an accident, and it cannot be weeded (but it can be replaced). It’s not an accident, because we need something to serve as the backbone that makes verbs “work”. We could try to describe things passively: “The ball falls due to gravity.” Describing things like this tends to not catch-on because we need an underlying metaphor to support our understanding, rather than just a list of facts. We need a language game.

The most common language game is that of agents and intent. I think it’s because our minds are biologically biased to think about everything as a person, because the most important thing to model is people. Hence the personification of everything in the myths of innumerable culture. I declare we should make the new language game focused on games. We can have players instead of agents and instead of being about intentions, let's make it about moves and patterns, about history. In many ways, this is similar to the difference between imperative and functional programming: instead of describing what things should do let’s describe what they are. 

Hence our historical definition of a superorganism is observational, we see through to the moves we know must have been played in order to keep a body in stasis. And we can take this further—we can describe the world as a series of operations, operations that make us intuit models of rules and moves, rather than saying we are sure about what someone else is constrained by. So, when I see someone flirting a certain way, I think “Well, if I was going to impersonate them, these are the rules I would play by”.