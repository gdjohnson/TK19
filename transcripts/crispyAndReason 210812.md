Main goals of call:

1. Hammer out “unit of survival” definition.
2. Connect dots on [[evolutionary epistemology]], paying rent/pragmatism, survival.
3. Go beyond mere memetic resonance into a real justification of how our ideas/theories can pay rent.
    1. For grant institutions: “[[science criticism]] is a missing part of the science ecosystem, which is why science is unhealthy.” Dr. Science. “Dr. Reason.”

[[Unit of Selection]]: comes out of a general discomfort at not having a distinction of “everythingness” that gets selected.

Crispy: Grandmas are the [[pfeilstorch]]s of group selection. (Classical reading: “A real evolutionary scientist would say, grandmas stick around for their own kid”)

“Conceptualization work”: theory, non-applied, etc. “The most valuable work that can be done in NLP”

Crispy: “The whole point of [[J.L. Austin]]'s' [[_How To Do Things With Words_]] is the way the speech act concept breaks down”—[[all communication is manipulation]]

Throwing an [[analogy]] like “selection” (as in [[selection game|selection games]]) at a domain: “This library works with this problem.” If you don’t have an existing assessment framework, you port one in analogically. (The standard protocol for mapping the [[foreign and familiar|foreign against the familiar]].)

[[Dallas Card]], on the phone with Crispy: [[Surrogation]] is missing a concept of “evolution.”

Crispy: “What happens with [[surrogation]] is the [[selection|selecting]] mechanism evolves to unselect (or fail to select) undesirable things, up until the point where the energy required for the selection mechanism = the amount of energy gained by letting in desirable things.” (See fraud, mimicry, [[frequency dependent selection]])

[[Dallas Card]]'s "emphasize midtermism in [[AI risk]] research" is a good take

[[Torque epistemology]]: how far it needs to push. Pricing strategy to how much you push. Sometimes, to get the public sentiment/funding/public attention where you want it to be, you have to push very hard in professional circles to have that proliferate out or the reverse. This is like vector projection, where you push in one direction, but only a little bit of that energy is transferred to the direction you want:

![[torque vector.png]]

Normal people are worrying about the wrong things with [[AI risk]]. But smart people might also get turned off, become [[torque epistemology|hipster-contrarians]]. There’s an [[elastic relationship]]. The rebound effect or breakage when you push too far. The further you push, the cheaper it is to push back. It is both less costly, in terms of social sanction—people are less willing to jump on you b/c your statements become less and less controversial/more and more obvious; similarly, the critiques are more available b/c they’re more available/obvious.

Realistically, everyone realizes there are a lot of crises in [[inexact sciences]]. No one believes visibility/[[open science]] will be the solution to everything. 

Pushing “[[science criticism|professional science critics]]” as our new tack—it’s clear for EDG/CW, we have [[Alexey Guzey]]/[[Sarah Perry|LiteralBanana]] precedents.

Layman science. Look at how science pays rent; if it doesn’t, ask why. If it’s testing a theory, we should figure out whether the theory pays rent. And if it doesn’t, we should be suspicious. We are the pragmatist [[science criticism|science critics]]. “What does the science *mean*” at the object level, to a layman.

[[Surrogation]] paying rent: “How should we think about psychometric results?”

Write/research literary criticism to learn about [[science criticism]] through analogy?

Crispy: We should care about the studies that get passed around on Twitter. If people are interested, good chance the findings matter i.e. they change behavior or attitudes. So the paying rent is built in.

> We want to figure out how we can make tools that are useful that are not not amenable to control trials. Our job is to look at useful things, define how they became useful, and capture how we can understand and use them in a way that doesn’t require us to definitively flip a bit (if I do X, Y, if I do Prime Y prime)—methods we use everyday. How can we formalize these patterns that aren’t statistically amenable, and show a) they’re already used, b) we can use this way of knowing to know more things.

[[Zero-sum competition]] and group selection; intra- vs inter-species fitness: If a group competes with itself in zero-sum games then it ends up getting outcompeted at a higher level of organization. Cooperation is what allows you to survive against higher-order (complexity-wise) adversaries.

 Shared vocabulary is especially likely to be misconstrued if it deals with non-measurable, intangible, too subjective to coordinate around. If a cult leader says “You can only join the inner ranks if you are holy,” everyone’s gonna fight.

[[Opticratics]] means people change their behavior to have a better public image—they don’t just “lie” they get cosmetic surgery, they start working out, they chase opportunities with a certain front-facing reputation, etc.

Chinese people are way more likely to lie. Westerners think it’s a human universal not to. The “people are basically good” [[bluepill]] is cultural. (See [[Friedrich Nietzsche]], [[slave morality]]. “It’s good b/c I want it” vs “It’s good b/c it doesn’t hurt anyone.” [[Peter Singer]], [[Toby Ord]], EA frame is the epitome of slave morality.)

[[bluepill]] starter pack (“Telling the truth is always best”)

“The hard problem of flirting”

[[Pragmatism]] is about mechanistic explanation: I do A, under context B, and get result C. Pragmatic explanations don’t always come in a mechanistic format; they can keep the context implicit, but what they’re ultimately about is prediction. We are predictive processing machines, and this is the natural epistemological frame for us. We are natural future modelers. [Banana quote on fragments escaping to cause mischief outta context ](https://carcinisation.com/2020/01/27/ignorance-a-skilled-practice/), cf [[indexicality]]. 

How does this tie into survival? [[evolutionary epistemology]]: A pragmatic agent would end up having good predictors because otherwise it wouldn’t survive.

One way torque epistemology pays rent is letting us talk about it. Crispy: “I’ve always thought of myself as a predictive processing proponent, but I didn’t like how people use the term.” The other alternative is that by seeding ourselves with certain metaphors we end up reproducing them. If you have a hammer… 

Phenomena transfer. Style transfer GAN—it’s not a global but a local transformation. We can’t do global transformations. Replicating deep structure is very hard; replicating shallow structure is easy—why we end up with babblers. Degrading quality of sentences in NLP output. Ben + my convo about fragments of emulation. Machine confuses itself and can’t go back. Things get complicated fast; the only way to explore a sparse space is to have a plan going into it. 

“The biggest game in [[complexity]] is whether something is exponential or non-exponential. Language is an [[exponential space]]. The space of allowed sentences is incredibly small. But the space of possible sentences is enormous. As a sentence goes on, it becomes larger and larger.”

Survival, mesa-optimizers vs base-optimizers in a rapidly changing environment

“Survival is always at the memetic level. The things that survive along with us are memetic—cf personhood as meme.”

It’s the fact of people having goals, within a situation of affordance and constraint—i.e. a language game—that allows them to create complex speech. The fact that they want to accomplish that is what even allows them to build complex structure in the first place; one cannot speak without the space of plans holding such speech up. “Awkwardness” is not knowing your goals and affordances. (Cf “Creepiness” as a kind of unpredictability.) It's a [[stigmergy|stigmergic]] approach to building over time, where you nudge things in the right direction, decision by decision, instead of having some over-arching plan.

“Paying rent, to me, is convincing a pragmatic agent that you have a mechanistic explanation that they can incorporate into their rituals that will give them more [[empowerment|intrinsic empowerment]] than they had previously.”

[Within the social game?] “Survival is hitting the socially recognizable goals that you intended to hit in the first place…. Maintaining a space where your predictive processing machine considers itself ’in scope’… Down to their models of when it’s acceptable to die.” Cf Banana’s inverted Maslow’s Hierarchy: the most important thing is social belong; everything else comes second. Consider [[S. I. Hayakawa]]’s example of saving the emperor’s picture from a burning building. People need to fulfill what they think they need to fulfill, it's just that a lot of that isn’t directly in our control to conceptualize. People will follow social codes even at the cost of their life.

[[functional pragmatism]]: words are what they do; Straussian reading of HTDTWW is functionally pragmatist: the unit of survival is memetic. But/For cause = causality: if X, then not Y; if not X, not Y. If part of DNA doesn’t turn up in phenotype, it doesn’t change selection going forward; in a random walk of history it won’t survive. Our interest in all this is simple—how can we establish useful frames of causality that allow us to talk about intentions and communication broadly the way we talk about intentions and communication when we are explaining a sitcom.
